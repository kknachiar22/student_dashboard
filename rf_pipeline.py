# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16va5-_f6j2Aq5Xp4faLhrSYSU6evTtPj
"""

import os
import pandas as pd
import numpy as np
import joblib
import logging
from datetime import datetime
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestRegressor
from sklearn.multioutput import MultiOutputRegressor
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler

# ─── Configuration ────────────────────────────────────────────────────────────
MODEL_DIR      = "models"
MODEL_PATH     = os.path.join(MODEL_DIR, "rf_model.pkl")
SCHEMA_PATH    = os.path.join(MODEL_DIR, "expected_features.pkl")
AUDIT_LOG_PATH = os.path.join(MODEL_DIR, "prediction_audit.csv")

os.makedirs(MODEL_DIR, exist_ok=True)
logging.basicConfig(
    filename=os.path.join(MODEL_DIR, "pipeline.log"),
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s"
)

# ─── 1. Preprocessing ─────────────────────────────────────────────────────────
def preprocess(df_raw: pd.DataFrame) -> pd.DataFrame:
    df = df_raw.copy()

    # Binary encode
    for col in ["father_work", "mother_work"]:
        df[col] = df[col].map({"yes": 1, "no": 0})

    # Ordinal encode Likert
    likert_map = {
        'Strongly disagree': 1, 'Disagree': 2,
        'Neutral':           3, 'Agree':    4,
        'Strongly agree':   5
    }
    for col in df.select_dtypes("object"):
        if set(df[col].unique()) & set(likert_map):
            df[col] = df[col].map(likert_map)

    # Encode absence_days
    def encode_absence(val):
        v = str(val)
        if v in ["0", "0.0"]:       return 0
        if v in ["1", "1_5", "1–5"]: return 1
        if v in ["5_10", "5–10"]:    return 2
        if v == ">10":               return 3
        return pd.NA

    df["absence_days"] = df["absence_days"].apply(encode_absence)

    # Drop identifiers
    df.drop(
        columns=['std_name','roll_number','fathers_name','mothers_name'],
        inplace=True, errors='ignore'
    )

    # One-hot encode branch
    df = pd.get_dummies(df, columns=["Branch"], drop_first=True)

    # Normalize exam_fail
    def normalize_fail(val):
        try:
            v = int(val)
            return 3 if v > 2 else v
        except:
            return pd.NA

    df["exam_fail"] = df["exam_fail"].apply(normalize_fail)

    # Drop any remaining NaN rows
    df.dropna(inplace=True)
    return df

# ─── 2. Training ───────────────────────────────────────────────────────────────
def train_and_save(df: pd.DataFrame) -> Pipeline:
    df_enc = preprocess(df)
    X = df_enc.loc[:, "father_work":"Confidence"]
    y = df_enc[["acad_percent","atten_percent"]]

    pipeline = Pipeline([
        ("imputer", SimpleImputer(strategy="mean")),
        ("scaler", StandardScaler()),
        ("model", MultiOutputRegressor(
            RandomForestRegressor(n_estimators=100, random_state=42)))
    ])
    pipeline.fit(X, y)

    joblib.dump(pipeline, MODEL_PATH)
    joblib.dump(list(X.columns), SCHEMA_PATH)
    logging.info("Trained and saved RF pipeline")
    return pipeline

# ─── 3. Load ─────────────────────────────────────────────────────────────────
def load_pipeline():
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError("Model file not found.")
    pipeline = joblib.load(MODEL_PATH)
    features = joblib.load(SCHEMA_PATH)
    return pipeline, features

# ─── 4. Predict & Log ────────────────────────────────────────────────────────
def predict_and_log(df_new: pd.DataFrame) -> pd.DataFrame:
    pipeline, features = load_pipeline()
    df_pre = preprocess(df_new)

    # Align columns
    df_pre = df_pre.reindex(columns=features, fill_value=0)
    preds = pipeline.predict(df_pre)

    df_out = df_new.reset_index(drop=True).copy()
    df_out["acad_pred"], df_out["atten_pred"] = preds[:,0], preds[:,1]

    # Audit
    audit = df_out[["acad_pred","atten_pred"]].copy()
    audit["timestamp"] = datetime.now()
    audit.to_csv(
        AUDIT_LOG_PATH, mode="a",
        header=not os.path.exists(AUDIT_LOG_PATH),
        index=False
    )
    logging.info("Logged %d predictions", len(df_out))
    return df_out